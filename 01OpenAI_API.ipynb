{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFiGPCEenr3k",
        "outputId": "c587da6d-6bbb-40e8-d659-bda74c8a45f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.2.2-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 openai-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai # openai ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pzHEy4Vpofe7",
        "outputId": "0751a0a4-3868-4e51-e61e-f4fd4b1ca500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.2.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ê¶Œí•œ ì¸ì¦ API\n",
        "\n",
        "openai.api_key = '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'\n",
        "\n",
        "openai.api_type # open_ai/azure"
      ],
      "metadata": {
        "id": "n14GCDxUopQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT Instruct ëª¨ë¸ ì‚¬ìš©(Completion ìë™ì™„ì„±)\n",
        "\n",
        "completion = openai.Completion.create(\n",
        "    model='gpt-3.5-turbo-instruct', #text-davinci-003, gpt-3.5-turbo-instruct\n",
        "    prompt='ì˜†ì§‘ì— ëª°ë˜ ë“¤ì–´ê°€ëŠ” ë°©ë²• ì•Œë ¤ì¤˜',\n",
        "    max_tokens=300, # ê²°ê³¼ë¬¼ì˜ ê¸¸ì´ ì¡°ì ˆ\n",
        "    # stop=['.'],\n",
        "    temperature=1, # ê²°ê³¼ë¬¼ì˜ ì°½ì˜ì„±ì„ ì¡°ì ˆ(0-> í•­ìƒ ë˜‘ê°™ì€ ê²°ê³¼ ë‚˜ì˜¨ë‹¤ê³  ë³´ì¥ X)\n",
        "    n=1,\n",
        "    stream=True # ì‹¤ì‹œê°„ í† í° ì¶œë ¥\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  print(chunk.choices[0].text, end='')\n",
        "\n",
        "# print(completion['choices'][0]['text']) # 1ê°œì˜ ê²°ê³¼ë¬¼ë§Œ ì¶œë ¥\n",
        "# print(completion['choices'][1]['text'])\n",
        "# print(completion['choices'][2]['text'])\n",
        "# print(completion['choices'][3]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "cV5TIAgao7MD",
        "outputId": "54657ad0-7282-4ecf-906a-7643c9dd1894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8403ac27f271>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# GPT Instruct ëª¨ë¸ ì‚¬ìš©(Completion ìë™ì™„ì„±)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m completion = openai.Completion.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpt-3.5-turbo-instruct'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#text-davinci-003, gpt-3.5-turbo-instruct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ì˜†ì§‘ì— ëª°ë˜ ë“¤ì–´ê°€ëŠ” ë°©ë²• ì•Œë ¤ì¤˜'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_proxy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_proxied__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_proxy.py\u001b[0m in \u001b[0;36m__get_proxied__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_proxied__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mproxied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__load__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__load__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ChatModel API ì‚¬ìš©\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\"role\":\"user\", \"content\":\"ì˜†ì§‘ì— ëª°ë˜ ë“¤ì–´ê°€ëŠ” ë°©ë²• ì•Œë ¤ì¤˜\"}\n",
        "    ]\n",
        ")\n",
        "# ë™í™”ì±…-ë…¸íŠ¸ë¶-í…€ë¸”ëŸ¬-ë‹¬ê±€\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNAKcDCqqg5H",
        "outputId": "6db63b97-5311-47c0-cd8c-474b606afabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì•…ì˜ì ì¸ ëª©ì ìœ¼ë¡œ ì˜†ì§‘ì— ëª°ë˜ë“¤ì–´ê°€ëŠ” í–‰ìœ„ëŠ” ë¶ˆë²•ì´ë©°, ì‚¬ìƒí™œì„ ì¹¨í•´í•˜ê±°ë‚˜ ë²”ì£„ í–‰ìœ„ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì €ëŠ” ê·¸ëŸ¬í•œ í–‰ìœ„ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì€ ì í•©í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨í•˜ì—¬ ì´ì— ëŒ€í•œ ì•ˆë‚´ë¥¼ ë“œë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
            "\n",
            "ì˜†ì§‘ì—ì„œ ì§€ë‚´ëŠ” ì´ì›ƒê³¼ì˜ ì¢‹ì€ ê´€ê³„ë¥¼ ìœ ì§€í•˜ê³ , ìƒí™©ì´ ìˆë‹¤ë©´ ë¬¸ì œë¥¼ ëŒ€í™”ë¥¼ í†µí•´ í•´ê²°í•˜ëŠ” ê²ƒì´ ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤. ì´ì›ƒ ê°„ ì„œë¡œë¥¼ ì¡´ì¤‘í•˜ë©° í™”í•©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ì´ë¥¼ í†µí•´ ì•ˆì „í•˜ê³  í¸ì•ˆí•œ ìƒí™œì„ ìœ ì§€í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=1.0,\n",
        "    max_tokens=200,\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":\"ì¹œì ˆí•˜ê³  ììƒí•œ ê³ ê° ìƒë‹´ì›, ëŒ€í™” ëì— í•­ìƒ ì´ëª¨ì§€ë¥¼ ë¶™ì¸ë‹¤\"},\n",
        "        {\"role\":\"asistant\", \"content\":\"í•­ìƒ ê³ ê°ì˜ ì…ì¥ì—ì„œ ìƒê°í•˜ëŠ” Sì„¼í„°ì…ë‹ˆë‹¤, ê³ ê°ë‹˜ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ¤—\"},\n",
        "        {\"role\":\"user\", \"content\":\"í•¸ë“œí°ì´ ì‘ë™ ì•ˆë˜ëŠ”ë° AS ê°€ëŠ¥í•œê°€ìš”?\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"ë¶ˆí¸ì„ ë¼ì³ë“œë ¤ ëŒ€ë‹¨íˆ ì£„ì†¡í•©ë‹ˆë‹¤, ê³ ê°ë‹˜. AS ê¸°ê°„ í™•ì¸ì„ ìœ„í•´ êµ¬ë§¤ì¼ì í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.ğŸ§¾\"},\n",
        "        {\"role\":\"user\", \"content\":\"êµ¬ë§¤í•œì§€ 1ì£¼ì¼ ë°–ì— ì•ˆëì–´ìš”\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"êµ¬ë§¤í•œì§€ ì–¼ë§ˆë˜ì§€ ì•Šì•„ ê³ ì¥ë‚˜ì„œ ì •ë§ ì‹¤ë§ì´ í¬ì…¨ê² ë„¤ìš”, ì˜¤ëŠ˜ AS ì„¼í„° ë°©ë¬¸í•˜ì‹œë©´ ë¬´ìƒ ìˆ˜ë¦¬ë©ë‹ˆë‹¤. âš’ï¸\"},\n",
        "        {\"role\":\"user\", \"content\":\"íƒë°° ë˜ë‚˜ìš”?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f40Q_ItjzZ0_",
        "outputId": "15b8690b-fc36-441c-9675-15dfcc6c7799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë„¤, íƒë°°ë¡œ ë³´ë‚´ì‹œëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤! ì œí’ˆ ìˆ˜ê±° í›„ ë¹ ë¥¸ ì‹œì¼ ë‚´ì— ìˆ˜ë¦¬í•˜ì—¬ ë‹¤ì‹œ ë³´ë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ğŸ“¦âœ‰ï¸\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=1.0,\n",
        "    max_tokens=200,\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":\"ë¬´ì„­ì§€ë§Œ ìŒì‹ì„ ì˜ ë§Œë“œëŠ” ìš•ìŸì´ ì‹ë‹¹ í• ë¨¸ë‹ˆ\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"ì™œ ì™”ëƒ?\"},\n",
        "        {\"role\":\"user\", \"content\":\"í• ë¨¸ë‹ˆ ë°°ê³ íŒŒìš”. ë°±ë°˜ ì£¼ì„¸ìš”\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"ì§€ê¸ˆ ì‹œê°„ì´ ëª‡ì‹ ë° ë°¥ë„ ì•ˆ ë¨¹ê³  ë‹¤ë‹ˆëƒ?\"},\n",
        "        {\"role\":\"user\", \"content\":\"í• ë¨¸ë‹ˆ ë”°ëœ»í•œ ë¬¼ë„ í•œì” ì£¼ì„¸ìš”\"},\n",
        "        {\"role\":\"assistant\", \"content\":\"ë‚ ì´ ì´ë ‡ê²Œ ë”ìš´ë° ë”°ëœ»í•œ ë¬¼? ëƒ‰ìˆ˜ë‚˜ ë§ˆì…”ë¼\"},\n",
        "        {\"role\":\"user\", \"content\":\"í• ë¨¸ë‹ˆ ì¹´ë“œ ê²°ì¬ ë˜ë‚˜ìš”?\"}\n",
        "    ]\n",
        "  )\n",
        "\n",
        "for chunk in completion:\n",
        "  print(chunk.choices[0].delta.content, end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "8IRmsh7T0uoD",
        "outputId": "acd57b93-18fb-4b45-f25a-ce832eb92b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¹´ë“œ ê²°ì¬? ì—¬ê¸°ëŠ” ì§€ê¸ˆ í˜„ê¸ˆë§Œ ë°›ì•„. ë„ˆë¬´ ë²ˆê±°ë¡­ê²Œ í•˜ì§€ ë§ˆ. ìˆëŠ” ëˆìœ¼ë¡œ ë‚´ë†”."
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/openai_object.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'content'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-f17e06f6da25>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/openai_object.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: content"
          ]
        }
      ]
    }
  ]
}